_wandb:
    value:
        cli_version: 0.21.3
        e:
            r2godibdd278tu8c70530a7aazubmu9t:
                args:
                    - --run=colab_t4_tiny_gpt01
                    - --depth=2
                    - --device_batch_size=2
                    - --num_iterations=40
                    - --eval_every=10
                    - --core_metric_every=999999
                    - --sample_every=10
                    - --total_batch_size=32768
                    - --max_seq_len=512
                cpu_count: 1
                cpu_count_logical: 2
                cudaVersion: "12.4"
                disk:
                    /:
                        total: "120942624768"
                        used: "52111192064"
                email: binarybrain.sahil@gmail.com
                executable: /content/nanochat/.venv/bin/python
                git:
                    commit: d6d86cbf4c0bcc1de5bbab28cae1f98038d0362a
                    remote: https://github.com/karpathy/nanochat.git
                gpu: Tesla T4
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Turing
                      cudaCores: 2560
                      memoryTotal: "16106127360"
                      name: Tesla T4
                      uuid: GPU-a1b787f8-1d05-1caf-93b2-b295dc43c360
                host: b6982fb209a3
                memory:
                    total: "13605855232"
                os: Linux-6.6.105+-x86_64-with-glibc2.35
                program: -m scripts.base_train
                python: CPython 3.10.12
                root: /content/nanochat
                startedAt: "2025-10-19T10:01:38.447269Z"
                writerId: r2godibdd278tu8c70530a7aazubmu9t
        m: []
        python_version: 3.10.12
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 2
                - 13
                - 16
            "4": 3.10.12
            "5": 0.21.3
            "12": 0.21.3
            "13": linux-x86_64
core_metric_every:
    value: 999999
core_metric_max_per_task:
    value: 500
depth:
    value: 2
device_batch_size:
    value: 2
embedding_lr:
    value: 0.2
eval_every:
    value: 10
eval_tokens:
    value: 10485760
grad_clip:
    value: 1
matrix_lr:
    value: 0.02
max_seq_len:
    value: 512
model_tag:
    value: ""
num_iterations:
    value: 40
run:
    value: colab_t4_tiny_gpt01
sample_every:
    value: 10
target_flops:
    value: -1
target_param_data_ratio:
    value: 20
total_batch_size:
    value: 32768
unembedding_lr:
    value: 0.004
weight_decay:
    value: 0
